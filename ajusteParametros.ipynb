{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\n",
    "        r\"https?:\\/\\/(www\\.)? ?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\. ?[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\",\n",
    "        \"\",\n",
    "        text,\n",
    "    )\n",
    "    text = re.sub(r\"(it | he | she | that)'s\", '\\1 is', text)\n",
    "    text = re.sub(r\"(they | we | you)'re\", '\\1 are', text)\n",
    "    text = re.sub(r\"youre\", 'you are', text)\n",
    "    text = re.sub(r\"(they | we | you)'ve\", '\\1 have', text)\n",
    "    text = re.sub(r\"this'\", 'this is', text)\n",
    "    text = re.sub(r\"http\", ' ', text)\n",
    "    text = re.sub(r\"i[']m\", 'i am', text)\n",
    "    text = re.sub(r\"didn[']t\", 'did not', text)\n",
    "    text = re.sub(r\"don[']t\", 'do not', text)\n",
    "    text = re.sub(r\"don[']t\", 'do not', text)\n",
    "    text = re.sub(r\"can't\", 'cannot', text)\n",
    "    text = re.sub(r\"&.+;\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('irony-labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'] = df['comment_text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>[... what? ](</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>does anybody remember during one of the debate...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>the pope is meeting a cruel dictator. likely w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  label\n",
       "1946                                      [... what? ](     -1\n",
       "1947  does anybody remember during one of the debate...     -1\n",
       "1948  the pope is meeting a cruel dictator. likely w...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('english')\n",
    "STOPWORDS.extend(['im', 'sourcehttpwww'])\n",
    "STOPWORDS = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    def convert(word):\n",
    "        word = re.sub(r\"\\W+\", \"\", word)\n",
    "        # Verifica se é um número.\n",
    "        try:\n",
    "            _ = float(word)\n",
    "            return '<num>'\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Verifica se é uma palavra.\n",
    "        if word.isalpha():\n",
    "            lower = word.lower()\n",
    "            return '<stop>' if lower in STOPWORDS else lower\n",
    "\n",
    "        # Caso contrário, é pontuação ou estranho.\n",
    "        return '<weird>'\n",
    "\n",
    "    processed = [convert(word) for word in sent]\n",
    "    forbidden_words = set(('<num>', '<stop>', '<weird>'))\n",
    "    return [word for word in processed if word not in forbidden_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i suspect atheists are projecting their desire...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[suspect, atheists, projecting, desires, imagi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's funny how the arguments the shills are ma...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[funny, arguments, shills, making, still, clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we are truly following the patterns of how the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[truly, following, patterns, mandarins, took, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  label  \\\n",
       "0  i suspect atheists are projecting their desire...     -1   \n",
       "1  it's funny how the arguments the shills are ma...     -1   \n",
       "2  we are truly following the patterns of how the...     -1   \n",
       "\n",
       "                                           word_list  \n",
       "0  [suspect, atheists, projecting, desires, imagi...  \n",
       "1  [funny, arguments, shills, making, still, clos...  \n",
       "2  [truly, following, patterns, mandarins, took, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_all = [preprocess(item.strip().split()) for item in df.comment_text]\n",
    "df['word_list'] = sents_all\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate LDA MODEL\n",
    "from gensim.models.ldamulticore import LdaMulticore, LdaModel\n",
    "def model_dict(sents, NUM_TOPICS):\n",
    "    dictionary = Dictionary(sents)\n",
    "    corpus = [dictionary.doc2bow(sent) for sent in sents]\n",
    "\n",
    "    ldamodel = LdaMulticore(corpus, num_topics=NUM_TOPICS, id2word=dictionary, passes=10, random_state=100, iterations=25)\n",
    "\n",
    "    return corpus, dictionary, ldamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check topics\n",
    "\n",
    "def check_topics(corpus, lda_model):\n",
    "    topics = lda_model.get_document_topics(corpus, per_word_topics=True)\n",
    "\n",
    "\n",
    "    doc_topics, word_topics, phi_values = topics[10]\n",
    "    print('Document topic:', doc_topics, \"\\n\")\n",
    "\n",
    "    for topic, strength in doc_topics:\n",
    "        print(f'Topico: {topic}')\n",
    "        print(lda_model.print_topic(topic, topn=20))\n",
    "\n",
    "    topics = lda_model.print_topics(num_words=10)\n",
    "    for topic in topics:\n",
    "        print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model(corpus, dictionary, ldamodel):  \n",
    "    lda_display = pyLDAvis.gensim_models.prepare(\n",
    "        ldamodel,\n",
    "        corpus,\n",
    "        dictionary,\n",
    "        sort_topics=False,\n",
    "    )\n",
    "    return pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts,  k, a, b,start=2, step=3):\n",
    "    # adaptado de https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "    model = LdaMulticore(corpus = corpus, num_topics=k, id2word=dictionary, random_state=100, passes=10, iterations=25, alpha=a, eta=b, chunksize=100)\n",
    "\n",
    "    coherencemodel = CoherenceModel(model=model, corpus=corpus, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "\n",
    "    return coherencemodel.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all = Dictionary(sents_all)\n",
    "corpus_all = [dictionary_all.doc2bow(sent) for sent in sents_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/540 [00:00<?, ?it/s]ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-552963b5a2b5>\", line 40, in <module>\n",
      "    cv = compute_coherence_values(dictionary=dictionary_all, corpus=corpus_sets[i], texts=sents_all,k=k, a=a, b=b)\n",
      "  File \"<ipython-input-13-28060efcce8f>\", line 6, in compute_coherence_values\n",
      "    model = LdaMulticore(corpus = corpus, num_topics=k, id2word=dictionary, random_state=100, passes=10, iterations=25, alpha=a, eta=b, chunksize=100)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\ldamulticore.py\", line 179, in __init__\n",
      "    super(LdaMulticore, self).__init__(\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\", line 523, in __init__\n",
      "    self.update(corpus, chunks_as_numpy=use_numpy)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\ldamulticore.py\", line 310, in update\n",
      "    process_result_queue(force=True)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\ldamulticore.py\", line 274, in process_result_queue\n",
      "    self.do_mstep(rho(), other, pass_ > 0)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\", line 1055, in do_mstep\n",
      "    self.state.blend(rho, other)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\ldamodel.py\", line 224, in blend\n",
      "    self.sstats *= (1.0 - rhot) * scale\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"c:\\users\\mathe\\appdata\\local\\programs\\python\\python38\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 124\n",
    "max_topics = 125\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus_all)\n",
    "corpus_sets = [corpus_all]\n",
    "corpus_title = ['100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(dictionary=dictionary_all, corpus=corpus_sets[i], texts=sents_all,k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interrompido, pois já temos o csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
